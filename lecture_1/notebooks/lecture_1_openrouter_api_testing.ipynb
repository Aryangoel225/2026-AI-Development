{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1 ‚Äî OpenRouter API Testing\n",
    "\n",
    "**Goal**: Explore different LLM models through OpenRouter API:\n",
    "\n",
    "1. Check account credit balance\n",
    "2. List available models with pricing\n",
    "3. Compare outputs from Claude vs free/cheap models\n",
    "4. Understand API request/response patterns\n",
    "5. Observe differences in model capabilities\n",
    "\n",
    "## Setup\n",
    "This notebook requires:\n",
    "- `OPENROUTER_API_KEY` (enter directly in Cell 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded\n",
      "Testing 6 models: ['claude', 'google-free', 'qwen-free', 'mistral', 'arcee', 'nvidia']\n",
      "‚úì API key configured\n"
     ]
    }
   ],
   "source": [
    "# Set up imports and API key\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get API key from environment variable\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\").strip()\n",
    "\n",
    "import json\n",
    "from typing import Any, Dict, List\n",
    "import pandas as pd\n",
    "\n",
    "from openrouter_utils import (\n",
    "    check_credits,\n",
    "    print_remaining_credits,\n",
    "    list_models,\n",
    "    chat_completion,\n",
    "    safe_chat,\n",
    "    display_comparison\n",
    ")\n",
    "\n",
    "# Models to test\n",
    "MODELS = {\n",
    "    \"claude\": \"anthropic/claude-3.5-sonnet\",\n",
    "    \"google-free\": \"google/gemma-3n-e2b-it:free\",\n",
    "    \"qwen-free\": \"qwen/qwen3-4b:free\",\n",
    "    \"mistral\" : \"mistralai/devstral-2512:free\",\n",
    "    \"arcee\": \"arcee-ai/trinity-mini:free\",\n",
    "    \"nvidia\": \"nvidia/nemotron-nano-9b-v2:free\"\n",
    "}\n",
    "\n",
    "print(\"Imports loaded\")\n",
    "print(f\"Testing {len(MODELS)} models:\", list(MODELS.keys()))\n",
    "\n",
    "if not OPENROUTER_API_KEY or OPENROUTER_API_KEY.strip() == \"\":\n",
    "    raise RuntimeError(\n",
    "        \"‚ö†Ô∏è  Please set OPENROUTER_API_KEY environment variable before running this notebook.\\n\"\n",
    "        \"Get your key from: https://openrouter.ai/keys\\n\"\n",
    "        \"Then set it with: export OPENROUTER_API_KEY='your-key-here'\"\n",
    "    )\n",
    "\n",
    "print(\"‚úì API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí≥ API Key Credit Balance:\n",
      "   Key limit:    $15.00\n",
      "   Key usage:    $0.03\n",
      "   Remaining:    $14.97\n"
     ]
    }
   ],
   "source": [
    "print_remaining_credits(OPENROUTER_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 models\n",
      "\n",
      "Our test models:\n",
      "  claude     ‚Üí anthropic/claude-3.5-sonnet (not found in list)\n",
      "  google-free ‚Üí google/gemma-3n-e2b-it:free (not found in list)\n",
      "  qwen-free  ‚Üí qwen/qwen3-4b:free (not found in list)\n",
      "  mistral    ‚Üí $0/1M prompt tokens\n",
      "  arcee      ‚Üí $0/1M prompt tokens\n",
      "  nvidia     ‚Üí $0/1M prompt tokens\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>prompt_cost</th>\n",
       "      <th>completion_cost</th>\n",
       "      <th>context_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allenai/molmo-2-8b:free</td>\n",
       "      <td>AllenAI: Molmo2 8B (free)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allenai/olmo-3.1-32b-instruct</td>\n",
       "      <td>AllenAI: Olmo 3.1 32B Instruct</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bytedance-seed/seed-1.6-flash</td>\n",
       "      <td>ByteDance Seed: Seed 1.6 Flash</td>\n",
       "      <td>0.000000075</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bytedance-seed/seed-1.6</td>\n",
       "      <td>ByteDance Seed: Seed 1.6</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minimax/minimax-m2.1</td>\n",
       "      <td>MiniMax: MiniMax M2.1</td>\n",
       "      <td>0.00000027</td>\n",
       "      <td>0.00000112</td>\n",
       "      <td>196608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>z-ai/glm-4.7</td>\n",
       "      <td>Z.AI: GLM 4.7</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>202752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google/gemini-3-flash-preview</td>\n",
       "      <td>Google: Gemini 3 Flash Preview</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1048576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mistralai/mistral-small-creative</td>\n",
       "      <td>Mistral: Mistral Small Creative</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>allenai/olmo-3.1-32b-think</td>\n",
       "      <td>AllenAI: Olmo 3.1 32B Think</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xiaomi/mimo-v2-flash:free</td>\n",
       "      <td>Xiaomi: MiMo-V2-Flash (free)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nvidia/nemotron-3-nano-30b-a3b:free</td>\n",
       "      <td>NVIDIA: Nemotron 3 Nano 30B A3B (free)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nvidia/nemotron-3-nano-30b-a3b</td>\n",
       "      <td>NVIDIA: Nemotron 3 Nano 30B A3B</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai/gpt-5.2-chat</td>\n",
       "      <td>OpenAI: GPT-5.2 Chat</td>\n",
       "      <td>0.00000175</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai/gpt-5.2-pro</td>\n",
       "      <td>OpenAI: GPT-5.2 Pro</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>openai/gpt-5.2</td>\n",
       "      <td>OpenAI: GPT-5.2</td>\n",
       "      <td>0.00000175</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mistralai/devstral-2512:free</td>\n",
       "      <td>Mistral: Devstral 2 2512 (free)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mistralai/devstral-2512</td>\n",
       "      <td>Mistral: Devstral 2 2512</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.00000022</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>relace/relace-search</td>\n",
       "      <td>Relace: Relace Search</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>z-ai/glm-4.6v</td>\n",
       "      <td>Z.AI: GLM 4.6V</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>131072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nex-agi/deepseek-v3.1-nex-n1</td>\n",
       "      <td>Nex AGI: DeepSeek V3.1 Nex N1</td>\n",
       "      <td>0.00000027</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>131072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0               allenai/molmo-2-8b:free   \n",
       "1         allenai/olmo-3.1-32b-instruct   \n",
       "2         bytedance-seed/seed-1.6-flash   \n",
       "3               bytedance-seed/seed-1.6   \n",
       "4                  minimax/minimax-m2.1   \n",
       "5                          z-ai/glm-4.7   \n",
       "6         google/gemini-3-flash-preview   \n",
       "7      mistralai/mistral-small-creative   \n",
       "8            allenai/olmo-3.1-32b-think   \n",
       "9             xiaomi/mimo-v2-flash:free   \n",
       "10  nvidia/nemotron-3-nano-30b-a3b:free   \n",
       "11       nvidia/nemotron-3-nano-30b-a3b   \n",
       "12                  openai/gpt-5.2-chat   \n",
       "13                   openai/gpt-5.2-pro   \n",
       "14                       openai/gpt-5.2   \n",
       "15         mistralai/devstral-2512:free   \n",
       "16              mistralai/devstral-2512   \n",
       "17                 relace/relace-search   \n",
       "18                        z-ai/glm-4.6v   \n",
       "19         nex-agi/deepseek-v3.1-nex-n1   \n",
       "\n",
       "                                      name  prompt_cost completion_cost  \\\n",
       "0                AllenAI: Molmo2 8B (free)            0               0   \n",
       "1           AllenAI: Olmo 3.1 32B Instruct    0.0000002       0.0000006   \n",
       "2           ByteDance Seed: Seed 1.6 Flash  0.000000075       0.0000003   \n",
       "3                 ByteDance Seed: Seed 1.6   0.00000025        0.000002   \n",
       "4                    MiniMax: MiniMax M2.1   0.00000027      0.00000112   \n",
       "5                            Z.AI: GLM 4.7    0.0000004       0.0000015   \n",
       "6           Google: Gemini 3 Flash Preview    0.0000005        0.000003   \n",
       "7          Mistral: Mistral Small Creative    0.0000001       0.0000003   \n",
       "8              AllenAI: Olmo 3.1 32B Think   0.00000015       0.0000005   \n",
       "9             Xiaomi: MiMo-V2-Flash (free)            0               0   \n",
       "10  NVIDIA: Nemotron 3 Nano 30B A3B (free)            0               0   \n",
       "11         NVIDIA: Nemotron 3 Nano 30B A3B   0.00000006      0.00000024   \n",
       "12                    OpenAI: GPT-5.2 Chat   0.00000175        0.000014   \n",
       "13                     OpenAI: GPT-5.2 Pro     0.000021        0.000168   \n",
       "14                         OpenAI: GPT-5.2   0.00000175        0.000014   \n",
       "15         Mistral: Devstral 2 2512 (free)            0               0   \n",
       "16                Mistral: Devstral 2 2512   0.00000005      0.00000022   \n",
       "17                   Relace: Relace Search     0.000001        0.000003   \n",
       "18                          Z.AI: GLM 4.6V    0.0000003       0.0000009   \n",
       "19           Nex AGI: DeepSeek V3.1 Nex N1   0.00000027        0.000001   \n",
       "\n",
       "    context_length  \n",
       "0            36864  \n",
       "1            65536  \n",
       "2           262144  \n",
       "3           262144  \n",
       "4           196608  \n",
       "5           202752  \n",
       "6          1048576  \n",
       "7            32768  \n",
       "8            65536  \n",
       "9           262144  \n",
       "10          256000  \n",
       "11          262144  \n",
       "12          128000  \n",
       "13          400000  \n",
       "14          400000  \n",
       "15          262144  \n",
       "16          262144  \n",
       "17          256000  \n",
       "18          131072  \n",
       "19          131072  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute - function is imported from openrouter_utils.py\n",
    "models_list = list_models(OPENROUTER_API_KEY, limit=100)\n",
    "\n",
    "# Parse into DataFrame for easy viewing\n",
    "models_df = pd.DataFrame([\n",
    "    {\n",
    "        \"id\": m.get(\"id\", \"\"),\n",
    "        \"name\": m.get(\"name\", \"\"),\n",
    "        \"prompt_cost\": m.get(\"pricing\", {}).get(\"prompt\", \"N/A\"),\n",
    "        \"completion_cost\": m.get(\"pricing\", {}).get(\"completion\", \"N/A\"),\n",
    "        \"context_length\": m.get(\"context_length\", \"N/A\"),\n",
    "    }\n",
    "    for m in models_list\n",
    "])\n",
    "\n",
    "print(f\"Found {len(models_df)} models\")\n",
    "print(\"\\nOur test models:\")\n",
    "for key, model_id in MODELS.items():\n",
    "    match = models_df[models_df[\"id\"] == model_id]\n",
    "    if not match.empty:\n",
    "        row = match.iloc[0]\n",
    "        print(f\"  {key:10s} ‚Üí ${row['prompt_cost']}/1M prompt tokens\")\n",
    "    else:\n",
    "        print(f\"  {key:10s} ‚Üí {model_id} (not found in list)\")\n",
    "\n",
    "# Display sample of all models\n",
    "models_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test prompts that showcase model differences\n",
    "\n",
    "PROMPTS = [\n",
    "    {\n",
    "        \"name\": \"Factual Q&A\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Explain what an API is in 2-3 sentences suitable for beginners.\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Reasoning Task\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"If I have 3 apples and buy 2 more, then give away half, how many do I have left? Show your reasoning.\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Code Explanation\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Explain what this Python code does: `[x**2 for x in range(5)]`\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Prompt: Factual Q&A\n",
      "============================================================\n",
      "\n",
      "Testing claude...\n",
      "  ‚úì Response: An API (Application Programming Interface) is like a waiter at a restaurant - it takes requests from one program and delivers them to another program, then returns with the results. It allows different software applications to communicate with each other using a set of predefined rules, making it possible for apps to share data and functionality without needing to know how the other program works internally.\n",
      "    Tokens: 25 prompt + 78 completion\n",
      "\n",
      "Testing google-free...\n",
      "  ‚úì Response: An API (Application Programming Interface) is like a menu for software. It allows different software programs to talk to each other and share information without needing to know the complex details of how each other works.  Essentially, it's a set of rules that lets developers request specific services from another application. \n",
      "\n",
      "    Tokens: 16 prompt + 60 completion\n",
      "\n",
      "Testing qwen-free...\n",
      "  ‚úì Response: An API (Application Programming Interface) is a set of rules that allows different software systems to communicate and share data. For example, when you use a weather app, it might use an API to fetch the latest weather data from a server. Think of it as a bridge that lets different programs talk to each other and exchange information.\n",
      "    Tokens: 723 prompt + 449 completion\n",
      "\n",
      "Testing mistral...\n",
      "  ‚úì Response: An **API (Application Programming Interface)** is like a messenger that allows different software programs to talk to each other. It defines a set of rules and tools that let apps share data or request services‚Äîlike when a weather app fetches updates from a server. Think of it as a waiter taking your order (request) to the kitchen (server) and bringing back your food (response).\n",
      "    Tokens: 20 prompt + 79 completion\n",
      "\n",
      "Testing arcee...\n",
      "  ‚úì Response: \n",
      "\n",
      "Think of an API likea waiter in a restaurant. You (the user/app) place an order (make a request) for something you need (like data or a function). The waiter (the API) takes your order to the kitchen (the server/service that has the information or can perform the action). The kitchen (server) then prepares your order and gives the result back to the waiter, who brings it to you. So, an API is the set of rules and tools that lets one piece of software talk to another and ask for what it needs.\n",
      "    Tokens: 25 prompt + 380 completion\n",
      "\n",
      "Testing nvidia...\n",
      "  ‚úì Response: An API (Application Programming Interface) is like a waiter in a restaurant: it takes requests from one software application (like a customer) and delivers them to another (like the kitchen), then returns the results back. It lets different programs communicate and share data without needing to understand each other's inner workings.\n",
      "\n",
      "    Tokens: 29 prompt + 292 completion\n",
      "\n",
      "============================================================\n",
      "Prompt: Reasoning Task\n",
      "============================================================\n",
      "\n",
      "Testing claude...\n",
      "  ‚úì Response: Let me solve this step by step:\n",
      "\n",
      "1. Initial amount: 3 apples\n",
      "2. Bought 2 more: 3 + 2 = 5 apples\n",
      "3. Give away half: 5 √∑ 2 = 2.5 apples\n",
      "\n",
      "Therefore, you have 2.5 apples left.\n",
      "    Tokens: 38 prompt + 84 completion\n",
      "\n",
      "Testing google-free...\n",
      "  ‚úì Response: Here's the breakdown:\n",
      "\n",
      "1. **Start:** You begin with 3 apples.\n",
      "2. **Buy more:** You buy 2 more apples, so you have 3 + 2 = 5 apples.\n",
      "3. **Give away half:** You give away half of your apples, which is 5 / 2 = 2.5 apples.  Since you can't give away half an apple, we'll assume you give away 2 apples (rounding down).\n",
      "4. **Remaining:** You started with 5 apples and gave away 2, so you have 5 - 2 = 3 apples left.\n",
      "\n",
      "**Therefore, you have 3 apples left.**\n",
      "    Tokens: 29 prompt + 125 completion\n",
      "\n",
      "Testing qwen-free...\n",
      "  ‚úì Response: If you start with 3 apples, buy 2 more, you have **5 apples**. Giving away half of 5 is **2.5 apples**. Therefore, you have **2.5 apples left**. \n",
      "\n",
      "**Step-by-Step Reasoning:**\n",
      "1. **Initial count:** 3 apples.\n",
      "2. **After buying 2 more:** $3 + 2 = 5$ apples.\n",
      "3.\n",
      "    Tokens: 735 prompt + 500 completion\n",
      "\n",
      "Testing mistral...\n",
      "  ‚úì Response: Let's break down the problem step by step:\n",
      "\n",
      "1. **Initial number of apples:**\n",
      "   You start with **3 apples**.\n",
      "\n",
      "2. **Buying more apples:**\n",
      "   You buy **2 more apples**.\n",
      "   So, total apples now = 3 + 2 = **5 apples**.\n",
      "\n",
      "3. **Giving away half:**\n",
      "   You give away half of the apples you have.\n",
      "   Half of 5 is 5 √∑ 2 = **2.5 apples**.\n",
      "   Since you can't have half an apple in this context, we'll assume you give away **2 apples** (the whole number part).\n",
      "\n",
      "4. **Apples left:**\n",
      "   Apples remaining = 5 - 2 = **3 apples**.\n",
      "\n",
      "**Final Answer:**\n",
      "You have **3 apples** left.\n",
      "    Tokens: 31 prompt + 161 completion\n",
      "\n",
      "Testing arcee...\n",
      "  ‚úì Response: \n",
      "    Tokens: 38 prompt + 500 completion\n",
      "\n",
      "Testing nvidia...\n",
      "  ‚úì Response: \n",
      "    Tokens: 40 prompt + 500 completion\n",
      "\n",
      "============================================================\n",
      "Prompt: Code Explanation\n",
      "============================================================\n",
      "\n",
      "Testing claude...\n",
      "  ‚úì Response: This is a list comprehension in Python that creates a list of squared numbers. Let's break it down:\n",
      "\n",
      "1. `range(5)` generates numbers from 0 to 4 (5 numbers total)\n",
      "2. `x**2` squares each number\n",
      "3. The entire expression creates a new list containing these squared values\n",
      "\n",
      "So the result would be:\n",
      "`[0, 1, 4, 9, 16]`\n",
      "\n",
      "Because:\n",
      "- 0¬≤ = 0\n",
      "- 1¬≤ = 1\n",
      "- 2¬≤ = 4\n",
      "- 3¬≤ = 9\n",
      "- 4¬≤ = 16\n",
      "\n",
      "It's a shorter way of writing:\n",
      "```python\n",
      "result = []\n",
      "for x in range(5):\n",
      "    result.append(x**2)\n",
      "```\n",
      "    Tokens: 29 prompt + 179 completion\n",
      "\n",
      "Testing google-free...\n",
      "  ‚úì Response: This Python code uses a list comprehension to create a new list. Let's break it down:\n",
      "\n",
      "* **`range(5)`:** This generates a sequence of numbers from 0 up to (but not including) 5. So, it produces the numbers 0, 1, 2, 3, and 4.\n",
      "\n",
      "* **`for x in range(5)`:** This part iterates through each number `x` in the sequence generated by `range(5)`.\n",
      "\n",
      "* **`x**2`:**  For each `x`, this calculates `x` raised to the power of 2 (i.e., `x` squared).\n",
      "\n",
      "* **`[...]`:** The square brackets enclose the entire expression.  This is the list comprehension syntax.  It tells Python to create a *new* list where each element is the result of the expression (`x**2`) evaluated for each value of `x` in the sequence.\n",
      "\n",
      "**In essence, the code calculates the square of each number from 0 to 4 and creates a list containing those squares.**\n",
      "\n",
      "**The resulting list will be:** `[0, 1, 4, 9, 16]`\n",
      "\n",
      "**Example:**\n",
      "\n",
      "If you were to run this code in a Python interpreter, it would produce the following output:\n",
      "\n",
      "```\n",
      "[0, 1, 4, 9, 16]\n",
      "```\n",
      "\n",
      "    Tokens: 21 prompt + 272 completion\n",
      "\n",
      "Testing qwen-free...\n",
      "  ‚ùå Error: HTTP 429: {\"error\":{\"message\":\"Provider returned error\",\"code\":429,\"metadata\":{\"raw\":\"qwen/qwen3-4b:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate l\n",
      "\n",
      "Testing mistral...\n",
      "  ‚úì Response: The Python code `[x**2 for x in range(5)]` is a **list comprehension** that generates a list of squares of numbers from 0 to 4. Here's a breakdown:\n",
      "\n",
      "### Explanation:\n",
      "1. **`range(5)`**\n",
      "   - This generates an iterable sequence of numbers from `0` to `4` (inclusive of `0`, exclusive of `5`).\n",
      "   - So, the values are: `0, 1, 2, 3, 4`.\n",
      "\n",
      "2. **`x**2`**\n",
      "   - This calculates the square of each number `x` in the sequence.\n",
      "\n",
      "3. **`[ ... ]` (List Comprehension)**\n",
      "   - The entire expression creates a new list where each element is the square of the corresponding number in `range(5)`.\n",
      "\n",
      "### Step-by-Step Execution:\n",
      "- For `x = 0`: `0**2 = 0`\n",
      "- For `x = 1`: `1**2 = 1`\n",
      "- For `x = 2`: `2**2 = 4`\n",
      "- For `x = 3`: `3**2 = 9`\n",
      "- For `x = 4`: `4**2 = 16`\n",
      "\n",
      "### Result:\n",
      "The final output is:\n",
      "```python\n",
      "[0, 1, 4, 9, 16]\n",
      "```\n",
      "\n",
      "### Equivalent Traditional Loop:\n",
      "This list comprehension is equivalent to:\n",
      "```python\n",
      "squares = []\n",
      "for x in range(5):\n",
      "    squares.append(x**2)\n",
      "```\n",
      "But the list comprehension is more concise and Pythonic.\n",
      "\n",
      "### Key Takeaway:\n",
      "- **List comprehensions** provide a compact way to create lists by applying an expression to each item in an iterable.\n",
      "- Here, it squares each number in `range(5)` and collects the results in a list.\n",
      "    Tokens: 23 prompt + 387 completion\n",
      "\n",
      "Testing arcee...\n",
      "  ‚úì Response: \n",
      "\n",
      "This Python code creates a new list using a **list comprehension**. Here's a breakdown of what it does:\n",
      "\n",
      "1.  **`range(5)`**: Generates a sequence of numbers starting from 0 up to (but not including) 5\n",
      "    Tokens: 29 prompt + 500 completion\n",
      "\n",
      "Testing nvidia...\n",
      "  ‚úì Response: The Python code `[x**2 for x in range(5)]` creates a list of the squares of numbers from 0 to 4. Here's a breakdown:\n",
      "\n",
      "1. **`range(5)`**: Generates numbers `0, 1, 2, 3, 4`.\n",
      "2. **`x`**: Iterates over each number in the range.\n",
      "3. **`x**2`**: Squares each number (e.g., `0¬≤=0`, `1¬≤=1`, `2¬≤=4`, etc.).\n",
      "4. **List comprehension**: Collects all squared values into a new list.\n",
      "\n",
      "**Result**: `[0, 1, 4, 9, 16\n",
      "    Tokens: 32 prompt + 500 completion\n",
      "\n",
      "‚úì All tests complete\n"
     ]
    }
   ],
   "source": [
    "# Run all prompts through all models\n",
    "\n",
    "results = []\n",
    "\n",
    "for prompt_obj in PROMPTS:\n",
    "    prompt_name = prompt_obj[\"name\"]\n",
    "    messages = prompt_obj[\"messages\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Prompt: {prompt_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for model_key, model_id in MODELS.items():\n",
    "        print(f\"\\nTesting {model_key}...\")\n",
    "        \n",
    "        result = chat_completion(\n",
    "            OPENROUTER_API_KEY,\n",
    "            model_id,\n",
    "            messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"prompt\": prompt_name,\n",
    "            \"model_key\": model_key,\n",
    "            \"model_id\": model_id,\n",
    "            **result\n",
    "        })\n",
    "        \n",
    "        # Display output\n",
    "        if result[\"error\"]:\n",
    "            print(f\"  ‚ùå Error: {result['error']}\")\n",
    "        else:\n",
    "            content = result[\"content\"]\n",
    "            preview = content\n",
    "            print(f\"  ‚úì Response: {preview}\")\n",
    "            \n",
    "            usage = result.get(\"usage\", {})\n",
    "            if usage:\n",
    "                print(f\"    Tokens: {usage.get('prompt_tokens', 0)} prompt + {usage.get('completion_tokens', 0)} completion\")\n",
    "\n",
    "print(\"\\n‚úì All tests complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 18 responses\n",
      "Errors: 1\n",
      "\n",
      "Summary by Model:\n",
      "             Errors  Avg Response Length  Total Tokens Used\n",
      "model_key                                                  \n",
      "arcee             0                233.7               1472\n",
      "claude            0                350.3                433\n",
      "google-free       0                591.7                523\n",
      "mistral           0                720.7                701\n",
      "nvidia            0                244.7               1393\n",
      "qwen-free         1                198.0               2407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_key</th>\n",
       "      <th>model_id</th>\n",
       "      <th>model</th>\n",
       "      <th>content</th>\n",
       "      <th>parsed_content</th>\n",
       "      <th>usage</th>\n",
       "      <th>error</th>\n",
       "      <th>response_length</th>\n",
       "      <th>has_error</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual Q&amp;A</td>\n",
       "      <td>claude</td>\n",
       "      <td>anthropic/claude-3.5-sonnet</td>\n",
       "      <td>anthropic/claude-3.5-sonnet</td>\n",
       "      <td>An API (Application Programming Interface) is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'prompt_tokens': 25, 'completion_tokens': 78,...</td>\n",
       "      <td>None</td>\n",
       "      <td>411</td>\n",
       "      <td>False</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual Q&amp;A</td>\n",
       "      <td>google-free</td>\n",
       "      <td>google/gemma-3n-e2b-it:free</td>\n",
       "      <td>google/gemma-3n-e2b-it:free</td>\n",
       "      <td>An API (Application Programming Interface) is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'prompt_tokens': 16, 'completion_tokens': 60,...</td>\n",
       "      <td>None</td>\n",
       "      <td>331</td>\n",
       "      <td>False</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual Q&amp;A</td>\n",
       "      <td>qwen-free</td>\n",
       "      <td>qwen/qwen3-4b:free</td>\n",
       "      <td>qwen/qwen3-4b:free</td>\n",
       "      <td>An API (Application Programming Interface) is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'prompt_tokens': 723, 'completion_tokens': 44...</td>\n",
       "      <td>None</td>\n",
       "      <td>337</td>\n",
       "      <td>False</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual Q&amp;A</td>\n",
       "      <td>mistral</td>\n",
       "      <td>mistralai/devstral-2512:free</td>\n",
       "      <td>mistralai/devstral-2512:free</td>\n",
       "      <td>An **API (Application Programming Interface)**...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'prompt_tokens': 20, 'completion_tokens': 79,...</td>\n",
       "      <td>None</td>\n",
       "      <td>381</td>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual Q&amp;A</td>\n",
       "      <td>arcee</td>\n",
       "      <td>arcee-ai/trinity-mini:free</td>\n",
       "      <td>arcee-ai/trinity-mini:free</td>\n",
       "      <td>\\n\\nThink of an API likea waiter in a restaura...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'prompt_tokens': 25, 'completion_tokens': 380...</td>\n",
       "      <td>None</td>\n",
       "      <td>499</td>\n",
       "      <td>False</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prompt    model_key                      model_id  \\\n",
       "0  Factual Q&A       claude   anthropic/claude-3.5-sonnet   \n",
       "1  Factual Q&A  google-free   google/gemma-3n-e2b-it:free   \n",
       "2  Factual Q&A    qwen-free            qwen/qwen3-4b:free   \n",
       "3  Factual Q&A      mistral  mistralai/devstral-2512:free   \n",
       "4  Factual Q&A        arcee    arcee-ai/trinity-mini:free   \n",
       "\n",
       "                          model  \\\n",
       "0   anthropic/claude-3.5-sonnet   \n",
       "1   google/gemma-3n-e2b-it:free   \n",
       "2            qwen/qwen3-4b:free   \n",
       "3  mistralai/devstral-2512:free   \n",
       "4    arcee-ai/trinity-mini:free   \n",
       "\n",
       "                                             content  parsed_content  \\\n",
       "0  An API (Application Programming Interface) is ...             NaN   \n",
       "1  An API (Application Programming Interface) is ...             NaN   \n",
       "2  An API (Application Programming Interface) is ...             NaN   \n",
       "3  An **API (Application Programming Interface)**...             NaN   \n",
       "4  \\n\\nThink of an API likea waiter in a restaura...             NaN   \n",
       "\n",
       "                                               usage error  response_length  \\\n",
       "0  {'prompt_tokens': 25, 'completion_tokens': 78,...  None              411   \n",
       "1  {'prompt_tokens': 16, 'completion_tokens': 60,...  None              331   \n",
       "2  {'prompt_tokens': 723, 'completion_tokens': 44...  None              337   \n",
       "3  {'prompt_tokens': 20, 'completion_tokens': 79,...  None              381   \n",
       "4  {'prompt_tokens': 25, 'completion_tokens': 380...  None              499   \n",
       "\n",
       "   has_error  total_tokens  \n",
       "0      False           103  \n",
       "1      False            76  \n",
       "2      False          1172  \n",
       "3      False            99  \n",
       "4      False           405  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to DataFrame for analysis\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Add computed fields\n",
    "results_df[\"response_length\"] = results_df[\"content\"].str.len()\n",
    "results_df[\"has_error\"] = results_df[\"error\"].notna()\n",
    "results_df[\"total_tokens\"] = results_df[\"usage\"].apply(\n",
    "    lambda u: u.get(\"total_tokens\", 0) if isinstance(u, dict) else 0\n",
    ")\n",
    "\n",
    "print(f\"Collected {len(results_df)} responses\")\n",
    "print(f\"Errors: {results_df['has_error'].sum()}\")\n",
    "\n",
    "# Summary by model\n",
    "summary = results_df.groupby(\"model_key\").agg({\n",
    "    \"has_error\": \"sum\",\n",
    "    \"response_length\": \"mean\",\n",
    "    \"total_tokens\": \"sum\"\n",
    "}).round(1)\n",
    "\n",
    "summary.columns = [\"Errors\", \"Avg Response Length\", \"Total Tokens Used\"]\n",
    "print(\"\\nSummary by Model:\")\n",
    "print(summary)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Prompt: Factual Q&A\n",
      "======================================================================\n",
      "\n",
      "[CLAUDE] (anthropic/claude-3.5-sonnet)\n",
      "----------------------------------------------------------------------\n",
      "An API (Application Programming Interface) is like a waiter at a restaurant - it takes requests from one program and delivers them to another program, then returns with the results. It allows different software applications to communicate with each other using a set of predefined rules, making it possible for apps to share data and functionality without needing to know how the other program works internally.\n",
      "\n",
      "Tokens: 103 total\n",
      "\n",
      "\n",
      "[GOOGLE-FREE] (google/gemma-3n-e2b-it:free)\n",
      "----------------------------------------------------------------------\n",
      "An API (Application Programming Interface) is like a menu for software. It allows different software programs to talk to each other and share information without needing to know the complex details of how each other works.  Essentially, it's a set of rules that lets developers request specific services from another application. \n",
      "\n",
      "\n",
      "Tokens: 76 total\n",
      "\n",
      "\n",
      "[QWEN-FREE] (qwen/qwen3-4b:free)\n",
      "----------------------------------------------------------------------\n",
      "An API (Application Programming Interface) is a set of rules that allows different software systems to communicate and share data. For example, when you use a weather app, it might use an API to fetch the latest weather data from a server. Think of it as a bridge that lets different programs talk to each other and exchange information.\n",
      "\n",
      "Tokens: 1172 total\n",
      "\n",
      "\n",
      "[MISTRAL] (mistralai/devstral-2512:free)\n",
      "----------------------------------------------------------------------\n",
      "An **API (Application Programming Interface)** is like a messenger that allows different software programs to talk to each other. It defines a set of rules and tools that let apps share data or request services‚Äîlike when a weather app fetches updates from a server. Think of it as a waiter taking your order (request) to the kitchen (server) and bringing back your food (response).\n",
      "\n",
      "Tokens: 99 total\n",
      "\n",
      "\n",
      "[ARCEE] (arcee-ai/trinity-mini:free)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Think of an API likea waiter in a restaurant. You (the user/app) place an order (make a request) for something you need (like data or a function). The waiter (the API) takes your order to the kitchen (the server/service that has the information or can perform the action). The kitchen (server) then prepares your order and gives the result back to the waiter, who brings it to you. So, an API is the set of rules and tools that lets one piece of software talk to another and ask for what it needs.\n",
      "\n",
      "Tokens: 405 total\n",
      "\n",
      "\n",
      "[NVIDIA] (nvidia/nemotron-nano-9b-v2:free)\n",
      "----------------------------------------------------------------------\n",
      "An API (Application Programming Interface) is like a waiter in a restaurant: it takes requests from one software application (like a customer) and delivers them to another (like the kitchen), then returns the results back. It lets different programs communicate and share data without needing to understand each other's inner workings.\n",
      "\n",
      "\n",
      "Tokens: 321 total\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Prompt: Reasoning Task\n",
      "======================================================================\n",
      "\n",
      "[CLAUDE] (anthropic/claude-3.5-sonnet)\n",
      "----------------------------------------------------------------------\n",
      "Let me solve this step by step:\n",
      "\n",
      "1. Initial amount: 3 apples\n",
      "2. Bought 2 more: 3 + 2 = 5 apples\n",
      "3. Give away half: 5 √∑ 2 = 2.5 apples\n",
      "\n",
      "Therefore, you have 2.5 apples left.\n",
      "\n",
      "Tokens: 122 total\n",
      "\n",
      "\n",
      "[GOOGLE-FREE] (google/gemma-3n-e2b-it:free)\n",
      "----------------------------------------------------------------------\n",
      "Here's the breakdown:\n",
      "\n",
      "1. **Start:** You begin with 3 apples.\n",
      "2. **Buy more:** You buy 2 more apples, so you have 3 + 2 = 5 apples.\n",
      "3. **Give away half:** You give away half of your apples, which is 5 / 2 = 2.5 apples.  Since you can't give away half an apple, we'll assume you give away 2 apples (rounding down).\n",
      "4. **Remaining:** You started with 5 apples and gave away 2, so you have 5 - 2 = 3 apples left.\n",
      "\n",
      "**Therefore, you have 3 apples left.**\n",
      "\n",
      "Tokens: 154 total\n",
      "\n",
      "\n",
      "[QWEN-FREE] (qwen/qwen3-4b:free)\n",
      "----------------------------------------------------------------------\n",
      "If you start with 3 apples, buy 2 more, you have **5 apples**. Giving away half of 5 is **2.5 apples**. Therefore, you have **2.5 apples left**. \n",
      "\n",
      "**Step-by-Step Reasoning:**\n",
      "1. **Initial count:** 3 apples.\n",
      "2. **After buying 2 more:** $3 + 2 = 5$ apples.\n",
      "3.\n",
      "\n",
      "Tokens: 1235 total\n",
      "\n",
      "\n",
      "[MISTRAL] (mistralai/devstral-2512:free)\n",
      "----------------------------------------------------------------------\n",
      "Let's break down the problem step by step:\n",
      "\n",
      "1. **Initial number of apples:**\n",
      "   You start with **3 apples**.\n",
      "\n",
      "2. **Buying more apples:**\n",
      "   You buy **2 more apples**.\n",
      "   So, total apples now = 3 + 2 = **5 apples**.\n",
      "\n",
      "3. **Giving away half:**\n",
      "   You give away half of the apples you have.\n",
      "   Half of 5 is 5 √∑ 2 = **2.5 apples**.\n",
      "   Since you can't have half an apple in this context, we'll assume you give away **2 apples** (the whole number part).\n",
      "\n",
      "4. **Apples left:**\n",
      "   Apples remaining = 5 - 2 = **3 apples**.\n",
      "\n",
      "**Final Answer:**\n",
      "You have **3 apples** left.\n",
      "\n",
      "Tokens: 192 total\n",
      "\n",
      "\n",
      "[ARCEE] (arcee-ai/trinity-mini:free)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Tokens: 538 total\n",
      "\n",
      "\n",
      "[NVIDIA] (nvidia/nemotron-nano-9b-v2:free)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Tokens: 540 total\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Prompt: Code Explanation\n",
      "======================================================================\n",
      "\n",
      "[CLAUDE] (anthropic/claude-3.5-sonnet)\n",
      "----------------------------------------------------------------------\n",
      "This is a list comprehension in Python that creates a list of squared numbers. Let's break it down:\n",
      "\n",
      "1. `range(5)` generates numbers from 0 to 4 (5 numbers total)\n",
      "2. `x**2` squares each number\n",
      "3. The entire expression creates a new list containing these squared values\n",
      "\n",
      "So the result would be:\n",
      "`[0, 1, 4, 9, 16]`\n",
      "\n",
      "Because:\n",
      "- 0¬≤ = 0\n",
      "- 1¬≤ = 1\n",
      "- 2¬≤ = 4\n",
      "- 3¬≤ = 9\n",
      "- 4¬≤ = 16\n",
      "\n",
      "It's a shorter way of writing:\n",
      "```python\n",
      "result = []\n",
      "for x in range(5):\n",
      "    result.append(x**2)\n",
      "```\n",
      "\n",
      "Tokens: 208 total\n",
      "\n",
      "\n",
      "[GOOGLE-FREE] (google/gemma-3n-e2b-it:free)\n",
      "----------------------------------------------------------------------\n",
      "This Python code uses a list comprehension to create a new list. Let's break it down:\n",
      "\n",
      "* **`range(5)`:** This generates a sequence of numbers from 0 up to (but not including) 5. So, it produces the numbers 0, 1, 2, 3, and 4.\n",
      "\n",
      "* **`for x in range(5)`:** This part iterates through each number `x` in the sequence generated by `range(5)`.\n",
      "\n",
      "* **`x**2`:**  For each `x`, this calculates `x` raised to the power of 2 (i.e., `x` squared).\n",
      "\n",
      "* **`[...]`:** The square brackets enclose the entire expression.  This is the list comprehension syntax.  It tells Python to create a *new* list where each element is the result of the expression (`x**2`) evaluated for each value of `x` in the sequence.\n",
      "\n",
      "**In essence, the code calculates the square of each number from 0 to 4 and creates a list containing those squares.**\n",
      "\n",
      "**The resulting list will be:** `[0, 1, 4, 9, 16]`\n",
      "\n",
      "**Example:**\n",
      "\n",
      "If you were to run this code in a Python interpreter, it would produce the following output:\n",
      "\n",
      "```\n",
      "[0, 1, 4, 9, 16]\n",
      "```\n",
      "\n",
      "\n",
      "Tokens: 293 total\n",
      "\n",
      "\n",
      "[QWEN-FREE] (qwen/qwen3-4b:free)\n",
      "----------------------------------------------------------------------\n",
      "‚ùå Error: HTTP 429: {\"error\":{\"message\":\"Provider returned error\",\"code\":429,\"metadata\":{\"raw\":\"qwen/qwen3-4b:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate l\n",
      "\n",
      "\n",
      "[MISTRAL] (mistralai/devstral-2512:free)\n",
      "----------------------------------------------------------------------\n",
      "The Python code `[x**2 for x in range(5)]` is a **list comprehension** that generates a list of squares of numbers from 0 to 4. Here's a breakdown:\n",
      "\n",
      "### Explanation:\n",
      "1. **`range(5)`**\n",
      "   - This generates an iterable sequence of numbers from `0` to `4` (inclusive of `0`, exclusive of `5`).\n",
      "   - So, the values are: `0, 1, 2, 3, 4`.\n",
      "\n",
      "2. **`x**2`**\n",
      "   - This calculates the square of each number `x` in the sequence.\n",
      "\n",
      "3. **`[ ... ]` (List Comprehension)**\n",
      "   - The entire expression creates a new list where each element is the square of the corresponding number in `range(5)`.\n",
      "\n",
      "### Step-by-Step Execution:\n",
      "- For `x = 0`: `0**2 = 0`\n",
      "- For `x = 1`: `1**2 = 1`\n",
      "- For `x = 2`: `2**2 = 4`\n",
      "- For `x = 3`: `3**2 = 9`\n",
      "- For `x = 4`: `4**2 = 16`\n",
      "\n",
      "### Result:\n",
      "The final output is:\n",
      "```python\n",
      "[0, 1, 4, 9, 16]\n",
      "```\n",
      "\n",
      "### Equivalent Traditional Loop:\n",
      "This list comprehension is equivalent to:\n",
      "```python\n",
      "squares = []\n",
      "for x in range(5):\n",
      "    squares.append(x**2)\n",
      "```\n",
      "But the list comprehension is more concise and Pythonic.\n",
      "\n",
      "### Key Takeaway:\n",
      "- **List comprehensions** provide a compact way to create lists by applying an expression to each item in an iterable.\n",
      "- Here, it squares each number in `range(5)` and collects the results in a list.\n",
      "\n",
      "Tokens: 410 total\n",
      "\n",
      "\n",
      "[ARCEE] (arcee-ai/trinity-mini:free)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "This Python code creates a new list using a **list comprehension**. Here's a breakdown of what it does:\n",
      "\n",
      "1.  **`range(5)`**: Generates a sequence of numbers starting from 0 up to (but not including) 5\n",
      "\n",
      "Tokens: 529 total\n",
      "\n",
      "\n",
      "[NVIDIA] (nvidia/nemotron-nano-9b-v2:free)\n",
      "----------------------------------------------------------------------\n",
      "The Python code `[x**2 for x in range(5)]` creates a list of the squares of numbers from 0 to 4. Here's a breakdown:\n",
      "\n",
      "1. **`range(5)`**: Generates numbers `0, 1, 2, 3, 4`.\n",
      "2. **`x`**: Iterates over each number in the range.\n",
      "3. **`x**2`**: Squares each number (e.g., `0¬≤=0`, `1¬≤=1`, `2¬≤=4`, etc.).\n",
      "4. **List comprehension**: Collects all squared values into a new list.\n",
      "\n",
      "**Result**: `[0, 1, 4, 9, 16\n",
      "\n",
      "Tokens: 532 total\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function is now imported from openrouter_utils.py\n",
    "# Display all comparisons\n",
    "for prompt_obj in PROMPTS:\n",
    "    display_comparison(results_df, prompt_obj[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running claude\n",
      "Running google-free\n",
      "Running qwen-free\n",
      "Running mistral\n",
      "Running arcee\n",
      "Running nvidia\n"
     ]
    }
   ],
   "source": [
    "# Structured Output Example: Extracting Laptop Specifications\n",
    "# This demonstrates extracting structured data from unstructured text\n",
    "\n",
    "laptop_description = \"\"\"\n",
    "Looking at this laptop listing, here's what I can tell you about it:\n",
    "\n",
    "I've been looking at this Dell XPS 15 9520 and it's really impressive. It's their premium 15-inch model, \n",
    "and honestly, the display is gorgeous - it's a 15.6 inch OLED screen with 3840x2400 resolution, so it's \n",
    "super sharp. The panel type is OLED which gives amazing contrast and colors, way better than my old laptop.\n",
    "\n",
    "For storage, the base model comes with a 512GB NVMe SSD, but the premium configuration I'm looking at \n",
    "has a 1TB NVMe SSD, which is pretty fast. The memory situation is interesting - the base model has 16GB \n",
    "of DDR5 RAM running at 4800MHz, while the premium version has 32GB. My current laptop only has 8GB, so \n",
    "even the base model would be twice the RAM I have now, which is pretty exciting. Both configurations can \n",
    "be upgraded to 64GB RAM if you need it later, which is nice for future-proofing.\n",
    "\n",
    "Under the hood, it's powered by an Intel Core i7-12700H processor, which is a 12th gen chip with 14 cores. \n",
    "The graphics card is an NVIDIA GeForce RTX 3050 Ti with 4GB of dedicated VRAM. One really cool feature \n",
    "that caught my attention is that it's compatible with external GPU docks if you need more graphics power \n",
    "down the line - that's pretty forward-thinking.\n",
    "\n",
    "Other features include: Wi-Fi 6E and Bluetooth 5.2 for connectivity, a 720p webcam (decent but not \n",
    "amazing), backlit keyboard which is always nice, and it weighs about 4.2 pounds - not the lightest but \n",
    "reasonable for a 15-inch. The battery is a 86Wh unit and they claim up to 10 hours of battery life, \n",
    "though I'd probably expect more like 7-8 in real use. It has 2 USB-C ports with Thunderbolt 4, 1 USB-A port, \n",
    "an HDMI 2.0 port, and a headphone jack. The operating system is Windows 11 Pro, and it's upgradeable to \n",
    "Windows 12 when that comes out, which is good to know.\n",
    "\n",
    "The build quality is solid - it's made of aluminum and carbon fiber, feels really premium. The price was \n",
    "$1,899 last month when I first looked at it, but it's currently on sale for $1,599 which is a pretty good \n",
    "deal. Actually, I saw another listing that says it's 30% off the original $2,000 MSRP, which would make \n",
    "it $1,400, but that might be a different seller or refurbished model - I'm not entirely sure.\n",
    "\n",
    "Overall, I think this is a solid choice, especially at the current sale price.\n",
    "\"\"\"\n",
    "\n",
    "# Define the extraction prompt with clear JSON schema\n",
    "extraction_prompt = f\"\"\"Extract all laptop specifications from the following text and return them as structured JSON.\n",
    "\n",
    "Text to analyze:\n",
    "{laptop_description}\n",
    "\n",
    "Extract the following information and return it as a JSON object with this exact structure:\n",
    "{{\n",
    "  \"brand\": \"string (e.g., Dell, HP, Lenovo)\",\n",
    "  \"model\": \"string (full model name/number)\",\n",
    "  \"screen_size\": number (in inches, e.g., 15.6),\n",
    "  \"screen_type\": \"string (e.g., OLED, IPS, LCD)\",\n",
    "  \"resolution\": \"string (e.g., 3840x2400)\",\n",
    "  \"storage\": {{\n",
    "    \"capacity\": number (in GB or TB, convert to GB),\n",
    "    \"type\": \"string (e.g., SSD, NVMe SSD, HDD)\"\n",
    "  }},\n",
    "  \"memory\": {{\n",
    "    \"amount_gb\": number (total RAM in GB),\n",
    "    \"type\": \"string (e.g., DDR4, DDR5)\",\n",
    "    \"speed_mhz\": number (if mentioned)\n",
    "  }},\n",
    "  \"processor\": {{\n",
    "    \"brand\": \"string (e.g., Intel, AMD)\",\n",
    "    \"model\": \"string (full processor name)\",\n",
    "    \"cores\": number,\n",
    "    \"generation\": \"string or number (if mentioned)\"\n",
    "  }},\n",
    "  \"graphics\": {{\n",
    "    \"type\": \"string (e.g., Integrated, Dedicated)\",\n",
    "    \"brand\": \"string (e.g., NVIDIA, AMD, Intel)\",\n",
    "    \"model\": \"string (e.g., RTX 3050 Ti)\",\n",
    "    \"vram_gb\": number (if dedicated GPU)\n",
    "  }},\n",
    "  \"connectivity\": {{\n",
    "    \"wifi\": \"string (e.g., Wi-Fi 6E, Wi-Fi 6)\",\n",
    "    \"bluetooth\": \"string (e.g., Bluetooth 5.2)\"\n",
    "  }},\n",
    "  \"ports\": {{\n",
    "    \"usb_c\": number,\n",
    "    \"usb_a\": number,\n",
    "    \"hdmi\": number,\n",
    "    \"other\": [\"string\"] (list other ports like headphone jack, etc.)\n",
    "  }},\n",
    "  \"battery\": {{\n",
    "    \"capacity_wh\": number,\n",
    "    \"estimated_hours\": number (if mentioned)\n",
    "  }},\n",
    "  \"weight_lbs\": number,\n",
    "  \"operating_system\": \"string\",\n",
    "  \"webcam\": \"string (resolution if mentioned)\",\n",
    "  \"keyboard\": [\"string\"] (list features like backlit, etc.),\n",
    "  \"build_materials\": [\"string\"] (list materials mentioned),\n",
    "  \"price\": {{\n",
    "    \"regular\": number (in USD, if mentioned),\n",
    "    \"sale\": number (in USD, if on sale)\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Important:\n",
    "- If a value is not mentioned in the text, use null for that field\n",
    "- Convert all storage to GB (1TB = 1024GB)\n",
    "- Extract exact numbers and strings as they appear\n",
    "- Return ONLY valid JSON, no additional text or markdown formatting\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": extraction_prompt}\n",
    "]\n",
    "\n",
    "output = {}\n",
    "for model in MODELS:\n",
    "\n",
    "    print(f\"Running {model}\")\n",
    "    \n",
    "    result = chat_completion(\n",
    "        OPENROUTER_API_KEY,\n",
    "        MODELS[model],\n",
    "        messages,\n",
    "        temperature=0.1,  # Very low temperature for consistent, accurate extraction\n",
    "        max_tokens=800,   # Enough tokens for detailed JSON\n",
    "        response_format={\"type\": \"json_object\"}  # Request JSON mode\n",
    "    )\n",
    "\n",
    "    output[model] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amount_gb': 32, 'type': 'DDR5', 'speed_mhz': 4800}\n",
      "Model google-free has no structured output\n",
      "Model qwen-free has no structured output\n",
      "{'amount_gb': 32, 'type': 'DDR5', 'speed_mhz': 4800}\n",
      "Model arcee has no structured output\n",
      "Model nvidia has no structured output\n"
     ]
    }
   ],
   "source": [
    "for model in output:\n",
    "    if not output[model].get('parsed_content'):\n",
    "        print(f\"Model {model} has no structured output\")\n",
    "        continue\n",
    "        \n",
    "    print(output[model]['parsed_content']['memory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information below contains a list of the highest level advertisting content categories used by advertisers:\n",
    "\n",
    "Sports\n",
    "Real Estate\n",
    "Hobbies & Interests\n",
    "Family and Relationships\n",
    "Entertainment\n",
    "Genres\n",
    "Events\n",
    "Personal Finance\n",
    "Pets\n",
    "Style & Fashion\n",
    "Attractions\n",
    "Law\n",
    "Careers\n",
    "Personal Celebrations & Life Events\n",
    "Medical Health\n",
    "Religion & Spirituality\n",
    "Healthy Living\n",
    "Food & Drink\n",
    "Home & Garden\n",
    "Communication\n",
    "Pop Culture\n",
    "Holidays\n",
    "Technology & Computing\n",
    "Automotive\n",
    "Travel\n",
    "Disasters\n",
    "Fine Art\n",
    "Sensitive Topics\n",
    "Science\n",
    "Books and Literature\n",
    "Business and Finance\n",
    "Politics\n",
    "Shopping\n",
    "War and Conflicts\n",
    "Education\n",
    "Video Gaming\n",
    "Crime\n",
    "\n",
    "for each of the websites below write code which takes the url in and tries to determine which category(s) it should be \n",
    "\n",
    "https://www.sfgate.com/hawaii/article/hawaii-eddie-aikau-surf-contest-21259632.php\n",
    "https://www.bbc.com/news/articles/c041dp0z95yo\n",
    "https://www.espn.com/nfl/playoff-bracket\n",
    "https://www.motortrend.com/features/best-off-road-vehicles\n",
    "https://www.allrecipes.com/gallery/best-canned-tuna-dinner-recipes/\n",
    "https://www.goodreads.com/list/show/29490.Best_Romance_Books_of_2012\n",
    "https://www.cancer.gov/about-cancer/treatment/side-effects/nutrition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test prompts that showcase model differences\n",
    "\n",
    "PROMPTS = [\n",
    "    {\n",
    "        \"name\": \"Classifying the website from the URL to category Question\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\"\"The information below contains a list of the highest level advertisting content categories used by advertisers:\n",
    "\n",
    "            Sports\n",
    "            Real Estate\n",
    "            Hobbies & Interests\n",
    "            Family and Relationships\n",
    "            Entertainment\n",
    "            Genres\n",
    "            Events\n",
    "            Personal Finance\n",
    "            Pets\n",
    "            Style & Fashion\n",
    "            Attractions\n",
    "            Law\n",
    "            Careers\n",
    "            Personal Celebrations & Life Events\n",
    "            Medical Health\n",
    "            Religion & Spirituality\n",
    "            Healthy Living\n",
    "            Food & Drink\n",
    "            Home & Garden\n",
    "            Communication\n",
    "            Pop Culture\n",
    "            Holidays\n",
    "            Technology & Computing\n",
    "            Automotive\n",
    "            Travel\n",
    "            Disasters\n",
    "            Fine Art\n",
    "            Sensitive Topics\n",
    "            Science\n",
    "            Books and Literature\n",
    "            Business and Finance\n",
    "            Politics\n",
    "            Shopping\n",
    "            War and Conflicts\n",
    "            Education\n",
    "            Video Gaming\n",
    "            Crime\n",
    "    for each of the websites browser through and try to determine which category(s) each website should be classified as:\n",
    "    https://www.sfgate.com/hawaii/article/hawaii-eddie-aikau-surf-contest-21259632.php\n",
    "    https://www.bbc.com/news/articles/c041dp0z95yo\n",
    "    https://www.espn.com/nfl/playoff-bracket\n",
    "    https://www.motortrend.com/features/best-off-road-vehicles\n",
    "    https://www.allrecipes.com/gallery/best-canned-tuna-dinner-recipes/\n",
    "    https://www.goodreads.com/list/show/29490.Best_Romance_Books_of_2012\n",
    "    https://www.cancer.gov/about-cancer/treatment/side-effects/nutrition\n",
    "\"\"\" \n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Prompt: Classifying the website from the URL to category Question\n",
      "============================================================\n",
      "\n",
      "Testing claude...\n",
      "  ‚úì Response: I'll analyze each website and classify them according to the provided categories:\n",
      "\n",
      "1. https://www.sfgate.com/hawaii/article/hawaii-eddie-aikau-surf-contest-21259632.php\n",
      "Categories:\n",
      "- Sports\n",
      "- Events\n",
      "\n",
      "2. https://www.bbc.com/news/articles/c041dp0z95yo\n",
      "(Without access to the specific article content, I cannot accurately categorize this one)\n",
      "\n",
      "3. https://www.espn.com/nfl/playoff-bracket\n",
      "Categories:\n",
      "- Sports\n",
      "\n",
      "4. https://www.motortrend.com/features/best-off-road-vehicles\n",
      "Categories:\n",
      "- Automotive\n",
      "\n",
      "5. https://www.allrecipes.com/gallery/best-canned-tuna-dinner-recipes/\n",
      "Categories:\n",
      "- Food & Drink\n",
      "\n",
      "6. https://www.goodreads.com/list/show/29490.Best_Romance_Books_of_2012\n",
      "Categories:\n",
      "- Books and Literature\n",
      "- Genres\n",
      "\n",
      "7. https://www.cancer.gov/about-cancer/treatment/side-effects/nutrition\n",
      "Categories:\n",
      "- Medical Health\n",
      "- Healthy Living\n",
      "    Tokens: 380 prompt + 264 completion\n",
      "\n",
      "Testing google-free...\n",
      "  ‚úì Response: Here's a breakdown of the website classifications based on the provided categories:\n",
      "\n",
      "*   **https://www.sfgate.com/hawaii/article/hawaii-eddie-aikau-surf-contest-21259632.php:** **Sports** (Specifically, surfing)\n",
      "\n",
      "*   **https://www.bbc.com/news/articles/c041dp0z95yo:** **News** (While not explicitly listed, news websites generally fall under this category, which is implied by the context of \"articles\").\n",
      "\n",
      "*   **https://www.espn.com/nfl/playoff-bracket:** **Sports** (Specifically, American Football - NFL)\n",
      "\n",
      "*   **https://www.motortrend.com/features/best-off-road-vehicles:** **Automotive**\n",
      "\n",
      "*   **https://www.allrecipes.com/gallery/best-canned-tuna-dinner-recipes/:** **Food & Drink**\n",
      "\n",
      "*   **https://www.goodreads.com/list/show/29490.Best_Romance_Books_of_2012:** **Books and Literature** (Specifically, Romance genre)\n",
      "\n",
      "*   **https://www.cancer.gov/about-cancer/treatment/side-effects/nutrition:** **Medical Health** (Specifically, nutrition related to cancer treatment)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Tokens: 376 prompt + 289 completion\n",
      "\n",
      "Testing qwen-free...\n",
      "  ‚úì Response: \n",
      "    Tokens: 1051 prompt + 500 completion\n",
      "\n",
      "Testing mistral...\n",
      "  ‚úì Response: Here‚Äôs the classification of each website based on the provided advertising content categories:\n",
      "\n",
      "1. **https://www.sfgate.com/hawaii/article/hawaii-eddie-aikau-surf-contest-21259632.php**\n",
      "   - **Sports** (Surfing contest)\n",
      "   - **Travel** (Hawaii-related content)\n",
      "\n",
      "2. **https://www.bbc.com/news/articles/c041dp0z95yo**\n",
      "   - **Politics** (BBC News often covers political topics)\n",
      "   - **War and Conflicts** (If the article is about a conflict)\n",
      "   - **Disasters** (If the article is about a natural disaster)\n",
      "   - *Note: Without the exact article content, this is a general classification based on BBC‚Äôs typical coverage.*\n",
      "\n",
      "3. **https://www.espn.com/nfl/playoff-bracket**\n",
      "   - **Sports** (NFL playoffs)\n",
      "\n",
      "4. **https://www.motortrend.com/features/best-off-road-vehicles**\n",
      "   - **Automotive** (Off-road vehicles)\n",
      "   - **Hobbies & Interests** (For off-roading enthusiasts)\n",
      "\n",
      "5. **https://www.allrecipes.com/gallery/best-canned-tuna-dinner-recipes/**\n",
      "   - **Food & Drink** (Recipes)\n",
      "   - **Healthy Living** (If focused on nutrition)\n",
      "\n",
      "6. **https://www.goodreads.com/list/show/29490.Best_Romance_Books_of_2012**\n",
      "   - **Books and Literature** (Romance books)\n",
      "   - **Genres** (Romance as a genre)\n",
      "\n",
      "7. **https://www.cancer.gov/about-cancer/treatment/side-effects/nutrition**\n",
      "   - **Medical Health** (Cancer treatment)\n",
      "   - **Healthy Living** (Nutrition advice)\n",
      "\n",
      "### Summary:\n",
      "- **Sports**: 1, 3\n",
      "- **Travel**: 1\n",
      "- **Politics/War/Disasters**: 2 (depends on article)\n",
      "- **Automotive**: 4\n",
      "- **Hobbies & Interests**: 4\n",
      "- **Food & Drink**: 5\n",
      "- **Healthy Living**: 5, 7\n",
      "- **Books and Literature**: 6\n",
      "- **Genres**: 6\n",
      "- **Medical Health**:\n",
      "    Tokens: 369 prompt + 500 completion\n",
      "\n",
      "Testing arcee...\n",
      "  ‚úì Response: \n",
      "    Tokens: 325 prompt + 500 completion\n",
      "\n",
      "Testing nvidia...\n",
      "  ‚úì Response: \n",
      "    Tokens: 378 prompt + 500 completion\n",
      "\n",
      "‚úì All tests complete\n"
     ]
    }
   ],
   "source": [
    "# Run all prompts through all models\n",
    "\n",
    "results = []\n",
    "\n",
    "for prompt_obj in PROMPTS:\n",
    "    prompt_name = prompt_obj[\"name\"]\n",
    "    messages = prompt_obj[\"messages\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Prompt: {prompt_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for model_key, model_id in MODELS.items():\n",
    "        print(f\"\\nTesting {model_key}...\")\n",
    "        \n",
    "        result = chat_completion(\n",
    "            OPENROUTER_API_KEY,\n",
    "            model_id,\n",
    "            messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"prompt\": prompt_name,\n",
    "            \"model_key\": model_key,\n",
    "            \"model_id\": model_id,\n",
    "            **result\n",
    "        })\n",
    "        \n",
    "        # Display output\n",
    "        if result[\"error\"]:\n",
    "            print(f\"  ‚ùå Error: {result['error']}\")\n",
    "        else:\n",
    "            content = result[\"content\"]\n",
    "            preview = content\n",
    "            print(f\"  ‚úì Response: {preview}\")\n",
    "            \n",
    "            usage = result.get(\"usage\", {})\n",
    "            if usage:\n",
    "                print(f\"    Tokens: {usage.get('prompt_tokens', 0)} prompt + {usage.get('completion_tokens', 0)} completion\")\n",
    "\n",
    "print(\"\\n‚úì All tests complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
